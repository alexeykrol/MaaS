# Test Scenario: FinalResponder (Step 8)

**–ú–æ–¥—É–ª—å:** `src/agents/index.ts` ‚Üí `runFinalResponder()`
**–®–∞–≥:** 8
**–¢–µ—Å—Ç—ã:** T8.1, T8.2, T8.3, T8.4, T8.5

---

## T8.1 ‚Äî OpenAI API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

### –ü—Ä–µ–¥—É—Å–ª–æ–≤–∏—è:
- `OPENAI_API_KEY` –≤ `.env`
- –ö–ª—é—á –≤–∞–ª–∏–¥–Ω—ã–π –∏ –∏–º–µ–µ—Ç credits

### –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è:
```typescript
import { testOpenAIConnection } from './utils/openai';
const ok = await testOpenAIConnection();
```

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
```
[INFO] [OpenAI] Testing connection...
[INFO] [OpenAI] Calling gpt-4o-mini...
[INFO] [OpenAI] Connection test successful: OK
```

---

## T8.2 ‚Äî –í—ã–∑–æ–≤ gpt-4o-mini

### –ö–æ–¥:
```typescript
const answer = await createChatCompletion({
  model: 'gpt-4o-mini',
  messages: [
    { role: 'system', content: 'You are a helpful AI assistant...' },
    { role: 'user', content: contextPayload }
  ],
  temperature: 0.7,
  max_tokens: 2000
});
```

### –õ–æ–≥:
```
[INFO] [FinalResponder] ü§ñ Calling OpenAI...
[INFO] [OpenAI] Calling gpt-4o-mini...
[INFO] [OpenAI] Completed in 1234ms {
  "model": "gpt-4o-mini",
  "tokens": 150,
  "prompt_tokens": 100,
  "completion_tokens": 50
}
[INFO] [FinalResponder] ‚úÖ OpenAI responded (256 chars)
```

---

## T8.3 ‚Äî –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ final_answer

### SQL:
```sql
UPDATE pipeline_runs
SET
  final_answer = $1,
  status = 'COMPLETED',
  updated_at = NOW()
WHERE id = $2
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞:
```sql
SELECT final_answer, status
FROM pipeline_runs
WHERE id = '{pipeline_id}';
```

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
- final_answer —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM
- status = 'COMPLETED'

---

## T8.4 ‚Äî –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ raw_logs

### –ö–æ–¥:
```typescript
// Log 1: USER_QUERY
await pool.query(
  `INSERT INTO raw_logs (pipeline_run_id, user_id, log_type, log_data)
   VALUES ($1, $2, 'USER_QUERY', $3)`,
  [pipelineId, run.user_id, JSON.stringify({ query, timestamp })]
);

// Log 2: SYSTEM_RESPONSE
await pool.query(
  `INSERT INTO raw_logs (pipeline_run_id, user_id, log_type, log_data)
   VALUES ($1, $2, 'SYSTEM_RESPONSE', $3)`,
  [pipelineId, run.user_id, JSON.stringify({ answer, timestamp })]
);
```

### SQL –ø—Ä–æ–≤–µ—Ä–∫–∞:
```sql
SELECT log_type, log_data
FROM raw_logs
WHERE pipeline_run_id = '{pipeline_id}'
ORDER BY created_at;
```

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
- 2 –∑–∞–ø–∏—Å–∏: USER_QUERY –∏ SYSTEM_RESPONSE
- log_data —Å–æ–¥–µ—Ä–∂–∏—Ç query/answer + timestamp

---

## T8.5 ‚Äî –°—Ç–∞—Ç—É—Å ‚Üí COMPLETED

### Flow:
```
READY ‚Üí RESPONDING ‚Üí COMPLETED
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞:
```sql
SELECT status FROM pipeline_runs WHERE id = '{pipeline_id}';
```

### –õ–æ–≥:
```
[INFO] [FinalResponder] ‚úÖ Completed for {pipeline_id}
[INFO] [Orchestrator] ‚úÖ Request completed: {pipeline_id}
```

---

## E2E —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å Orchestrator
npm run orchestrator

# 2. –°–æ–∑–¥–∞—Ç—å –∑–∞–ø—Ä–æ—Å
INSERT INTO pipeline_runs (user_id, status, user_query)
VALUES ('test-user-id', 'NEW', 'What is 2+2?');

# 3. –ù–∞–±–ª—é–¥–∞—Ç—å –ª–æ–≥–∏:
# - Analyzer extracts keywords
# - Assembler builds context
# - FinalResponder calls OpenAI
# - Status becomes COMPLETED

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
SELECT user_query, final_answer, status
FROM pipeline_runs
ORDER BY created_at DESC
LIMIT 1;
```

---

## Error Handling

### OpenAI –æ—à–∏–±–∫–∏:
```typescript
if (error.status === 401) {
  throw new Error('OpenAI API key is invalid or missing');
} else if (error.status === 429) {
  throw new Error('OpenAI rate limit exceeded');
}
```

### Pipeline –æ—à–∏–±–∫–∏:
- –ü—Ä–∏ –æ—à–∏–±–∫–µ ‚Üí status = 'FAILED'
- error_message —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ

---

## –°—Ç–∞—Ç—É—Å

| –¢–µ—Å—Ç | –°—Ç–∞—Ç—É—Å | –î–∞—Ç–∞ |
|------|--------|------|
| T8.1 | ‚úÖ PASSED | 2025-11-25 |
| T8.2 | ‚úÖ PASSED | 2025-11-25 |
| T8.3 | ‚úÖ PASSED | 2025-11-25 |
| T8.4 | ‚úÖ PASSED | 2025-11-25 |
| T8.5 | ‚úÖ PASSED | 2025-11-25 |
