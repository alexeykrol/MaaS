# LSM: Long-term Semantic Memory

> **Статус:** v1.0 — базовая спецификация
> **Последнее обновление:** 2025-12-01

---

## Оглавление

1. [Иерархия требований](#1-иерархия-требований)
2. [Требования к памяти](#2-требования-к-памяти)
3. [Обоснование архитектуры](#3-обоснование-архитектуры)
4. [Архитектура памяти](#4-архитектура-памяти)
5. [Связанные документы](#5-связанные-документы)

---

## 1. Иерархия требований

Требования к LSM вытекают из цепочки:

```
AI Mentor Agent → MaaS → LSM (память)
```

### 1.1 Требования к AI Mentor Agent

AI Mentor — это персональный ассистент, который:

| ID | Требование | Обоснование |
|----|------------|-------------|
| **A1** | Помнит историю взаимодействий | Ментор должен знать, что обсуждали раньше |
| **A2** | Понимает контекст пользователя | Знает проекты, предпочтения, стиль общения |
| **A3** | Даёт персонализированные ответы | Не generic, а с учётом истории |
| **A4** | Развивается со временем | Качество растёт от взаимодействия к взаимодействию |
| **A5** | Работает долгосрочно | Месяцы и годы, не одна сессия |

### 1.2 Требования к MaaS (Memory as a Service)

MaaS — инфраструктура памяти для AI Mentor:

| ID | Требование | Источник |
|----|------------|----------|
| **M1** | Хранить диалоги долгосрочно | A1, A5 |
| **M2** | Быстро находить релевантный контекст | A1, A3 |
| **M3** | Сжимать старую информацию | A5 (экономия ресурсов) |
| **M4** | Извлекать структурированные факты | A2 (сущности, решения) |
| **M5** | Поддерживать обучение системы | A4 (self-learning) |
| **M6** | Масштабироваться по объёму | A5 (годы данных) |

### 1.3 Требования к LSM (память)

LSM — конкретная реализация памяти в MaaS:

| ID | Требование | Источник | Приоритет |
|----|------------|----------|-----------|
| **L1** | Хранить сырые логи диалогов | M1 | MUST |
| **L2** | Создавать семантические саммари | M3, M4 | MUST |
| **L3** | Поддерживать поиск по семантике | M2 | MUST |
| **L4** | Поддерживать поиск по ключевым словам/тегам | M2 | MUST |
| **L5** | Разделять горячие и холодные данные | M3, M6 | MUST |
| **L6** | Восстанавливать контекст по запросу | M2 | MUST |
| **L7** | Хранить связи между эпизодами | M4 | SHOULD |
| **L8** | Поддерживать "якоря" (постоянная память) | M1 (профиль, настройки) | SHOULD |
| **L9** | Предоставлять метрики для self-learning | M5 | SHOULD |

---

## 2. Требования к памяти

### 2.1 Функциональные требования

#### F1: Запись диалогов
```
Вход: сырой диалог (user_query + assistant_response)
Выход: запись в raw_logs + создание/обновление эпизода
Критерий: 100% диалогов сохраняются
```

#### F2: Поиск по контексту
```
Вход: текущий запрос пользователя
Выход: релевантный исторический контекст
Критерий:
  - Если контекст существует — находим в 95% случаев
  - Latency < 500ms
```

#### F3: Саммаризация
```
Вход: эпизод из горячего слоя
Выход: сжатое представление для тёплого/холодного слоя
Критерий:
  - Сохранение ключевых сущностей: 100%
  - Сохранение решений: 100%
  - Коэффициент сжатия: 3-10x
```

#### F4: Распаковка
```
Вход: запрос на детали из холодного/тёплого слоя
Выход: восстановленный полный контекст
Критерий: по восстановленному контексту можно ответить на 80%+ вопросов
```

#### F5: Миграция между слоями
```
Вход: эпизод + триггер (время, доступ)
Выход: эпизод в новом слое с соответствующим форматом
Критерий: автоматическая, без потери критичных данных
```

### 2.2 Нефункциональные требования

| ID | Требование | Значение | Обоснование |
|----|------------|----------|-------------|
| **NF1** | Latency поиска | < 500ms | UX: ответ должен быть быстрым |
| **NF2** | Объём горячего слоя | 14 дней или N токенов | Баланс качества и стоимости |
| **NF3** | Retention | Бессрочно (cold) | A5: долгосрочная работа |
| **NF4** | Compression ratio | 3-10x (hot→warm), 10-20x (warm→cold) | M6: масштабируемость |
| **NF5** | Availability | 99% | Критичный компонент |

### 2.3 Ограничения

| Ограничение | Значение | Причина |
|-------------|----------|---------|
| Контекстное окно LLM | ~128K токенов | Технический лимит |
| Стоимость API | $0.01-0.03 / 1K токенов | Бюджет |
| Latency LLM | 1-5 сек | Технический лимит |

---

## 3. Обоснование архитектуры

### 3.1 Почему анизотропная память?

**Проблема:** Нельзя хранить всё в одном формате.

| Подход | Проблема |
|--------|----------|
| Всё raw | Не влезает в контекст LLM, дорого искать |
| Всё summary | Теряются детали, плохое качество ответов |
| Плоский индекс | Не учитывает актуальность, всё одинаково |

**Решение:** Разная плотность хранения в зависимости от актуальности.

```
Актуальность = f(Recency, Frequency, Importance, TaskRelevance)
```

Это соответствует человеческой памяти:
- Недавнее помню детально
- Давнее помню в общих чертах
- Важное помню всегда

**Вывод:** L5 (разделение горячих/холодных данных) → анизотропная архитектура.

### 3.2 Почему три слоя?

**Анализ требований:**

| Требование | Нужно для горячего | Нужно для холодного |
|------------|-------------------|---------------------|
| L2 (саммари) | ❌ не нужно | ✅ нужно |
| L3 (семантический поиск) | ❌ exact match | ✅ по эмбеддингам |
| L6 (восстановление) | ❌ уже доступно | ✅ нужна распаковка |

**Проблема:** Резкий переход hot→cold теряет слишком много.

**Решение:** Промежуточный тёплый слой с градиентом сжатия.

```
Hot (0-14 дней)     → 0% сжатия, полный доступ
Warm (14д - 3 мес)  → 30-70% сжатия, быстрый поиск
Cold (3+ мес)       → 90% сжатия, только индекс
```

### 3.3 Почему эпизод, а не сообщение?

**Требование L7:** хранить связи между эпизодами.

**Проблема:** Если атом = сообщение:
- Слишком много единиц хранения
- Теряется контекст (одно сообщение бессмысленно)
- Сложно отслеживать связи

**Решение:** Атом = эпизод (связанный блок вокруг темы/задачи).

```
Эпизод = {
  тема: "Обсуждение архитектуры LSM",
  сообщения: [msg1, msg2, ..., msgN],
  сущности: [MaaS, LSM, Archivist],
  решения: ["Используем 3 слоя", "Анизотропный подход"],
  связи: [предыдущий_эпизод, связанный_проект]
}
```

### 3.4 Почему ленивая распаковка?

**Требования:** L6 (восстановление) + NF1 (latency).

**Проблема:** Если всегда восстанавливать полностью:
- Долго (загрузка raw_logs)
- Дорого (токены)
- Часто не нужно

**Решение:** Двухэтапный поиск.

```
Шаг 1: Быстрый поиск по саммари/эмбеддингам
       → "Нашёл релевантный эпизод"

Шаг 2: Решение о глубине
       → Достаточно саммари? → Ответ по саммари
       → Нужны детали? → Распаковка + реактуализация
```

**Реактуализация:** После распаковки эпизод возвращается в горячий слой (обновляется приоритет).

### 3.5 Почему разные алгоритмы саммаризации?

**Требование L2** + разные цели слоёв.

| Переход | Цель | Что сохранить | Что убрать |
|---------|------|---------------|------------|
| Hot→Warm | Возможность ответить на вопросы | Решения, сущности, факты | Small-talk, промежуточные шаги |
| Warm→Cold | Навигация ("надо ли копать") | Суть, теги, эмбеддинг | Детали решений, контекст |

**Вывод:** Один промпт саммаризации не подходит. Нужны разные алгоритмы для разных переходов.

→ См. [PACKING.md](./PACKING.md)

---

## 4. Архитектура памяти

### 4.1 Ключевой принцип: Анизотропия

Память **неоднородна**. Качество, скорость доступа и детализация зависят от **актуальности**.

```
Актуальность = f(Recency, Frequency, Importance, TaskRelevance)
```

Чем выше актуальность — тем выше целостность (больше связей, больше деталей).

### 4.2 Три слоя памяти

#### Слой 1: Горячий (Hot) — 0-14 дней

| Параметр | Значение |
|----------|----------|
| **Плотность** | 0% (raw text) |
| **Формат** | Полные логи диалогов |
| **Доступ** | Мгновенный, всегда в контексте |
| **Связи** | Максимальные (scale-free network) |

**Поведение:** Всё помнится детально, "на кончиках пальцев".

#### Слой 2: Тёплый (Warm) — 14 дней - 3 месяца

| Параметр | Значение |
|----------|----------|
| **Плотность** | 30-70% (градиент) |
| **Формат** | Summary + ключевые факты + эмбеддинг |
| **Доступ** | Быстрый поиск по индексу |
| **Связи** | Частичные (основные сохранены) |

**Поведение:** Помнится общая картина, детали размыты.

#### Слой 3: Холодный (Cold) — 3+ месяцев

| Параметр | Значение |
|----------|----------|
| **Плотность** | 90% (стандартный пакет) |
| **Формат** | Минимальное семантическое поле |
| **Доступ** | Только по запросу |
| **Связи** | Минимальные или отсутствуют |

**Поведение:** "Да, это было" — но без деталей.

### 4.3 Эпизод — атом памяти

Единица хранения — не сообщение, а **эпизод** (связанный блок вокруг одной темы/задачи).

```typescript
interface Episode {
  id: UUID;

  // Временной контекст
  created_at: Timestamp;
  last_accessed: Timestamp;

  // Слой и приоритет
  layer: 'hot' | 'warm' | 'cold';
  priority: number;  // 0.0 - 1.0

  // Семантика (зависит от слоя)
  content: HotContent | WarmContent | ColdContent;

  // Связи
  continues_from: UUID | null;
  related_to: UUID[];

  // Якорь (не теряет приоритет)
  is_anchor: boolean;

  // Ссылка на сырые данные
  raw_log_ids: UUID[];
}
```

#### Контент по слоям

```typescript
// Горячий — полный текст
interface HotContent {
  raw_messages: Message[];
  entities: Entity[];
  decisions: Decision[];
}

// Тёплый — сжатый
interface WarmContent {
  summary: string;           // 2-4 предложения
  key_points: string[];      // Буллеты
  entities: Entity[];
  decisions: Decision[];
  embedding: Vector;
}

// Холодный — минимальный
interface ColdContent {
  headline: string;          // 1 предложение "о чём это"
  tags: string[];
  embedding: Vector;
}
```

### 4.4 Приоритет и миграция

#### Формула приоритета

```typescript
function calculatePriority(episode: Episode): number {
  const recency = decay(daysSince(episode.last_accessed));  // 0-0.3
  const frequency = normalize(episode.access_count);         // 0-0.2
  const importance = episode.is_anchor ? 0.3 : 0;            // 0 или 0.3
  const relevance = cosineSimilarity(episode.embedding, currentQueryEmbedding); // 0-0.2

  return recency + frequency + importance + relevance;
}
```

#### Пороги миграции

```
P > 0.7    → Горячий
0.3 < P ≤ 0.7 → Тёплый
P ≤ 0.3   → Холодный
```

#### Триггеры миграции

**Вниз (автоматическая):**
```
Hot → Warm: 14 дней без обращения
Warm → Cold: 3 месяца без обращения
```

**Вверх (по запросу):**
```
Cold → Hot: глубокая распаковка
Warm → Hot: активное использование
```

### 4.5 Алгоритм поиска: Ленивая распаковка

```
Запрос пользователя
       ↓
[1] Поиск в горячем слое (exact match)
       ↓
    Найдено? → Ответ с полным контекстом
       ↓
    Не найдено
       ↓
[2] Поиск в тёплом/холодном (по эмбеддингам)
       ↓
    Найден релевантный эпизод
       ↓
[3] Оценка: "Достаточно ли summary?"
       ↓
    ┌──────┴──────┐
    ↓             ↓
   ДА            НЕТ
    ↓             ↓
  Ответ по     Распаковка +
  summary      реактуализация
```

### 4.6 Якоря (Anchors)

Некоторые эпизоды не должны терять приоритет:
- Профиль пользователя
- Долгосрочные проекты
- Явно помеченные ("запомни это навсегда")
- Системные инструкции

```typescript
if (episode.is_anchor) {
  episode.priority = Math.max(episode.priority, ANCHOR_MIN_PRIORITY);
  // Никогда не мигрирует в холодный слой
}
```

### 4.7 Схема базы данных

```sql
episodes:
  id UUID PRIMARY KEY,
  layer VARCHAR(10),           -- 'hot', 'warm', 'cold'
  priority FLOAT,
  is_anchor BOOLEAN DEFAULT FALSE,

  created_at TIMESTAMP,
  last_accessed TIMESTAMP,
  access_count INTEGER DEFAULT 0,

  content_hot JSONB,           -- для hot слоя
  content_warm JSONB,          -- для warm слоя
  content_cold JSONB,          -- для cold слоя

  embedding VECTOR(1536),      -- OpenAI embedding

  continues_from UUID REFERENCES episodes(id),
  related_to UUID[],
  raw_log_ids UUID[]           -- ссылки на raw_logs
```

---

## 5. Связанные документы

| Документ | Описание |
|----------|----------|
| [PACKING.md](./PACKING.md) | Алгоритм семантической упаковки |
| [LSM_DESIGN.md](./LSM_DESIGN.md) | Исторический черновик (deprecated) |
| [m_*.md](.) | Брейнсторминг-документы от разных AI |
| [ARCHITECTURE.md](../../ARCHITECTURE.md) | Общая архитектура MaaS |
| [PROJECT_INTAKE.md](../../PROJECT_INTAKE.md) | Требования к проекту |

---

## Changelog

| Версия | Дата | Изменения |
|--------|------|-----------|
| v1.0 | 2025-12-01 | Первая версия с иерархией требований |

---

*Этот документ является основной спецификацией LSM. При изменениях архитектуры памяти обновлять в первую очередь этот документ.*
