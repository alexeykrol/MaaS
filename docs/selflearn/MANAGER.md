Ок, давай «разработческое» описание Менеджера как модуля.

---

## Менеджер (Experiment Manager / Coordinator)

### 0. Назначение

Менеджер — это **центральный координирующий модуль**, который:

* принимает цели/ограничения от мета-пользователя (через фронт);
* переводит их в **формальные задачи** для Учителя, Симулятора и Настройщика;
* управляет жизненным циклом экспериментов и циклов самообучения;
* агрегирует результаты и возвращает их мета-пользователю в виде отчётов;
* следит за соблюдением политик автономии (что системе «разрешено» менять без человека).

Он **не** оценивает качество (это роль Учителя) и **не** трогает параметры напрямую (это Настройщик). Его зона — координация и протокол.

---

### 1. Границы ответственности

**Менеджер ДЕЛАЕТ:**

* принимает цели, приоритеты и ограничения от мета-пользователя;
* формирует и регистрирует эксперименты;
* вызывает Учителя для дизайна/анализа экспериментов;
* вызывает Симулятор для генерации данных;
* вызывает Настройщика для применения/отката параметров;
* ведёт «журнал обучения» и историю решений;
* генерирует человекочитаемые отчёты.

**Менеджер НЕ ДЕЛАЕТ:**

* не придумывает гипотез (что именно крутить и в какую сторону) — это Учитель;
* не считает метрики «сырых» логов — максимум вызывает готовые агрегаты/запросы;
* не меняет `experiment_parameters` напрямую;
* не лезет в пайплайн MaaS.

---

### 2. Интерфейсы (входы/выходы)

#### 2.1. Входы от мета-пользователя

Через фронт:

* цели обучения:

  * типичные форматы:

    * «снизить hallucination_rate по персональной памяти < 3%»;
    * «увеличить recall по preferences на +10%»;
    * «оптимизировать стоимость при сохранении текущего качества».
* ограничения:

  * что нельзя трогать (модели, RLS, типы данных);
  * max latency / max cost / max error_rate;
  * уровень автономии (что можно менять без подтверждения).
* приоритеты:

  * «главное — качество памяти» / «главное — дешево»;
  * порядок целей, если они конфликтуют.

#### 2.2. Входы от внутренних модулей

* от Учителя:

  * описания экспериментов (структура Experiment);
  * результаты экспериментов (metrics + verdict);
  * рекомендации по изменению параметров;
* от Настройщика:

  * статусы операций (успешно/ошибка);
  * информация об активных версиях параметров;
* от Симулятора:

  * статус прогонов (сколько диалогов прогнано, ошибки);
  * ссылка на собранную телеметрию.

#### 2.3. Выходы

* к Учителю:

  * формальные задания:

    * «спроектировать эксперимент под такие цели/constraints»;
    * «проанализировать результаты конкретного experiment_id»;
* к Симулятору:

  * команды запуска/остановки прогонов:

    * какие сценарии использовать;
    * какие варианты параметров тестировать (baseline/variant);
    * объём тестов (N диалогов, M шагов в каждом);
* к Настройщику:

  * заявки на изменения параметров:

    * подготовить экспериментальные конфигурации;
    * применить/откатить найденные изменения;
* к фронту/мета-пользователю:

  * дашборды / summary / логи решений.

---

### 3. Внутренняя структура Менеджера

Можно мыслить как набор подмодулей/сервисов:

1. **Goal Translator**

   * Принимает «человеческие» формулировки от мета-пользователя.
   * Превращает их в:

     * целевые метрики (primary/secondary);
     * допустимые импакт-факторы;
     * уровень автономии (auto/manual).

2. **Experiment Orchestrator**

   * Создаёт сущности `Experiment`:

     * id, цель, параметры, variants, success criteria.
   * Координирует:

     * запрос к Учителю (дизайн/анализ),
     * запуск Симулятора,
     * сбор статуса.
   * Отслеживает жизненный цикл эксперимента:

     * `planned → running → completed → analyzed`.

3. **Policy & Guardrail Manager**

   * Хранит и проверяет политики:

     * что можно тюнить автоматически;
     * разрешённые диапазоны параметров;
     * лимиты на число параллельных экспериментов;
     * уровни критичности (что требует ручного подтверждения).
   * Валидирует рекомендации Учителя перед тем, как отправить их Настройщику.

4. **Change Log & History**

   * Ведёт «журнал обучения»:

     * какие эксперименты запускались;
     * какие изменения параметров применены;
     * почему (ссылка на эксперименты и метрики);
     * кто инициировал (auto/manual).
   * Даёт API для фронта: «покажи историю изменений за период».

5. **Reporting & UX Layer**

   * Подготавливает человекочитаемые отчёты:

     * summary по экспериментам;
     * графики по ключевым метрикам (по данным из Telemetry);
     * алерты и рекомендации в понятном виде.

---

### 4. Основные сценарии работы Менеджера

#### 4.1. Новый цель/кампания обучения

1. Мета-пользователь задаёт через UI цель и ограничения.
2. Goal Translator:

   * валидирует ввод (есть ли нужные метрики, не конфликтуют ли constraints);
   * создаёт запись «кампании»/learning goal.
3. Менеджер вызывает Учителя:

   * «спроектируй набор экспериментов под эту goal».
4. Учитель возвращает набор `Experiment` → сохраняется в registry.

#### 4.2. Запуск эксперимента

1. Менеджер выбирает, какие эксперименты активировать (можно по очереди или пачкой).
2. Проверяет с Policy Manager:

   * не превышены ли лимиты;
   * не конфликтуют ли эксперименты по одним и тем же параметрам.
3. Формирует задачу Симулятору:

   * какие сценарии использовать;
   * split по вариантам (baseline/variant);
   * размер выборки.
4. Присваивает experiment_id, переводит эксперимент в статус `running`.

#### 4.3. Завершение и анализ

1. По условию (кол-во диалогов или время) Менеджер закрывает эксперимент как `completed`.
2. Запрашивает Учителя:

   * «проанализируй experiment_id, дай verdict и рекомендации».
3. Получает от Учителя:

   * winner/loser/inconclusive;
   * delta по метрикам;
   * предложения по изменению параметров + условия rollback.

#### 4.4. Применение изменений

1. Менеджер прогоняет рекомендации через Policy Manager:

   * допустимы ли такие изменения в авто-режиме;
   * нужно ли подтверждение мета-пользователя.
2. Если требуется approval:

   * показывает summary в UI;
   * ждёт явного «approve/reject».
3. После разрешения:

   * отправляет Настройщику формализованную «команду изменения параметров».
4. Логирует факт изменения и привязку к experiment_id.

#### 4.5. Обработка деградаций

1. Настройщик или Учитель сигналят о деградации (по DEGRADATION_RULES).
2. Менеджер:

   * фиксирует инцидент;
   * инициирует rollback через Настройщика;
   * создаёт запись в журнале;
   * показывает в UI «авто-откат по причине X».

---

### 5. Артефакты, с которыми работает Менеджер

* **Learning goals / campaigns**

  * id, цели, приоритеты, constraints, статус.
* **Experiments registry**

  * список экспериментов, статусы, ссылки на метрики.
* **Policies / guardrails**

  * описания разрешённых автономных действий.
* **Change log**

  * список параметр-изменений с причинами.
* **Reports**

  * сохранённые отчёты по циклам обучения (для UI).

---

### 6. Метрики качества самого Менеджера

Чего от него ждать и как понять, что он «нормально работает», а не превращается в болото:

* **Velocity:**

  * время от постановки цели до первого эксперимента;
  * время от завершения эксперимента до принятия решения.
* **Coverage:**

  * доля актуальных learning goals, по которым есть хотя бы один запущенный эксперимент.
* **Consistency:**

  * нет конфликтующих изменений одного параметра в разных экспериментах без явного разрешения.
* **Safety:**

  * нет изменений вне разрешённых политик;
  * количество авто-откатов по вине неправильной координации Менеджера ≈ 0.

---

### 7. Риски по роли Менеджера

Коротко, чтобы помнить при дизайне:

* риск 1: Менеджер становится «god-object» — тащит всё подряд. Нужно жёстко держать границу: он не считает метрики и не лезет в бизнес-логику Учителя.
* риск 2: путаница состояний экспериментов → нужен простой, но строгий lifecycle (`planned/running/completed/analyzed/applied/rolled_back`).
* риск 3: UI/Менеджер начинают обходить Настройщика и писать напрямую в конфиги — этого быть не должно вообще.

---

Если нужно, следующим шагом могу:

* свернуть всё это в секцию `### 1.2. Менеджер — спецификация` в стиле твоего `SELFLEARN.md`, или
* сделать skeleton для `MANAGER.md` (артефакты → API → сценарии → команды для агента).
