# MANAGER — координатор системы самообучения

> **Ключевая идея:** Manager — это **мета-агент**, который сам реализует goal-oriented project по улучшению MaaS.

---

## 0. Парадигма: Manager как Meta-Agent

### Рекурсия паттерна

```
Уровень 1: Диалог Ученик-Учитель = Goal-Oriented Project
                ↓
Уровень 2: Self-Learning Cycle = Goal-Oriented Project (мета-уровень)
                ↓
Manager = Agent с собственным meta-prompt, ToDo, целью, памятью
```

### Почему это важно

Manager — не просто "координатор", который вызывает функции. Он:
- Имеет **собственную цель** (довести MaaS до target metrics)
- Ведёт **внутренний ToDo** (как Claude Code)
- Принимает **решения** о следующих шагах
- Управляет **асинхронными задачами** параллельно

### Схема

```
┌─────────────────────────────────────────────────────────────────┐
│                    MANAGER (Meta-Agent)                         │
│                                                                 │
│  meta_prompt: {mission, targets, methodology, constraints}      │
│  state: {current_metrics, todo_list, experiment_history}        │
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                    LEARNING CYCLE                        │   │
│  │                                                          │   │
│  │   ┌──────────┐    ┌──────────┐    ┌──────────┐          │   │
│  │   │ Emulate  │───►│ Evaluate │───►│  Tune    │──┐       │   │
│  │   │ (N=30)   │    │ (gap?)   │    │ (apply)  │  │       │   │
│  │   └──────────┘    └──────────┘    └──────────┘  │       │   │
│  │        ▲                                        │       │   │
│  │        └────────────────────────────────────────┘       │   │
│  │                     (repeat until targets met)          │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
                         ┌─────────┐
                         │  MaaS   │
                         │(Ученик) │
                         └─────────┘
```

---

## 0.1. Meta-Prompt Manager'а

```markdown
# Meta-Prompt: Self-Learning Manager

## Миссия
Довести MaaS до целевых метрик через циклы экспериментов.

## Текущие цели (targets)
- Precision: > 80% (текущий: {current_precision})
- Recall: > 70% (текущий: {current_recall})
- Hallucination: < 5% (текущий: {current_hallucination})
- Context Utilization: > 90% (текущий: {current_context_util})

## Методология
1. Запустить N эмулированных диалогов (default: 30)
2. Собрать метрики через Sensor + Teacher
3. Вычислить gap для каждой метрики: gap = target - current
4. Если gap > threshold:
   - Определить какой impact factor влияет на метрику (см. IMPACTS.md)
   - Сформировать гипотезу изменения
   - Запустить A/B эксперимент
5. Применить изменения через Tuner
6. Повторить цикл

## Ограничения
- Не менять больше 1 impact factor за цикл
- Откат если метрика ухудшилась на > 10%
- Макс 10 циклов на эксперимент
- Соблюдать уровни автономии (см. AUTONOMY.md)

## Текущий ToDo
- [ ] Эмуляция batch_{id}: {status}
- [ ] Оценка batch_{id}: {status}
- [ ] Тюнинг experiment_{id}: {status}
```

---

## 0.2. Target Metrics (Целевые метрики)

> **Gap = Target - Current** — основа для принятия решений

### Таблица targets

| Метрика | Target | Threshold | Приоритет |
|---------|--------|-----------|-----------|
| Hallucination Rate | < 5% | gap > 2% | Critical |
| Retrieval Precision | > 80% | gap > 10% | Primary |
| Retrieval Recall | > 70% | gap > 10% | Primary |
| Context Utilization | > 90% | gap > 5% | Primary |
| Latency P95 | < 5s | gap > 1s | Secondary |
| Error Rate | < 1% | gap > 0.5% | Secondary |

### Логика принятия решений

```typescript
interface MetricGap {
  metric: string;
  target: number;
  current: number;
  gap: number;          // target - current (или current - target для "меньше лучше")
  threshold: number;
  exceeds_threshold: boolean;
  priority: 'critical' | 'primary' | 'secondary';
}

function shouldTune(gaps: MetricGap[]): boolean {
  // Если любая critical метрика превышает threshold — обязательно тюнить
  const criticalGaps = gaps.filter(g => g.priority === 'critical' && g.exceeds_threshold);
  if (criticalGaps.length > 0) return true;

  // Если primary метрики в среднем плохие — тюнить
  const primaryGaps = gaps.filter(g => g.priority === 'primary');
  const avgPrimaryGap = primaryGaps.reduce((sum, g) => sum + g.gap, 0) / primaryGaps.length;
  return avgPrimaryGap > 5; // более 5% в среднем
}
```

---

## 0.3. Асинхронный Learning Cycle

Manager управляет **параллельными задачами**:

```
Manager
    │
    ├── Task 1: Эмуляция (запускается async)
    │       ├── Emulator генерирует N диалогов
    │       ├── Student Agent ←→ Teacher Agent
    │       ├── Sensor пишет в sensor_events
    │       └── Status: pending → running → completed
    │
    ├── Task 2: Оценка (после завершения Task 1)
    │       ├── Teacher анализирует sensor_events
    │       ├── LLM-judge оценивает качество
    │       ├── Вычисляет gaps для всех метрик
    │       └── Формирует verdict + recommendations
    │
    └── Task 3: Тюнинг (если gaps > thresholds)
            ├── Выбирает impact factor для изменения
            ├── Tuner применяет изменение
            └── → Следующий цикл (Task 1)
```

### State Machine для цикла

```
┌─────────┐     start      ┌───────────┐    complete    ┌───────────┐
│  IDLE   │───────────────►│ EMULATING │───────────────►│ EVALUATING│
└─────────┘                └───────────┘                └─────┬─────┘
     ▲                                                        │
     │                                                        ▼
     │         no gaps      ┌───────────┐    has gaps   ┌───────────┐
     └──────────────────────│  TUNING   │◄──────────────│ ANALYZING │
                            └───────────┘               └───────────┘
```

---

## 0.4. Правило внешней валидации (Goodhart Protection)

> **Проблема Goodhart:** "Когда мера становится целью, она перестаёт быть хорошей мерой."

Без внешнего якоря система может оптимизировать метрики, не улучшая реальное качество памяти.

### Обязательное правило

```
⚠️ ЛЮБОЕ изменение impact factors считается успешным ТОЛЬКО если:

1. Метрики на Golden Dataset улучшились или не ухудшились
2. Golden Dataset НЕ используется в эмуляции — только для валидации
3. Если golden metrics ухудшились на > 5% → автоматический rollback
```

### Golden Dataset как внешний якорь

```
┌─────────────────────────────────────────────────────────────────┐
│                    LEARNING CYCLE                                │
│                                                                  │
│   Emulated Dialogues (train)        Golden Dataset (test)        │
│   ┌─────────────────────┐          ┌─────────────────────┐      │
│   │ Генерируются        │          │ Фиксированный набор │      │
│   │ эмулятором          │          │ НЕ меняется         │      │
│   │ Используются для    │          │ НЕ используется в   │      │
│   │ обучения            │          │ обучении            │      │
│   └──────────┬──────────┘          └──────────┬──────────┘      │
│              │                                 │                  │
│              ▼                                 ▼                  │
│   ┌─────────────────────┐          ┌─────────────────────┐      │
│   │ Teacher анализирует │          │ Финальная проверка  │      │
│   │ → гипотеза          │          │ ПЕРЕД применением   │      │
│   └──────────┬──────────┘          └──────────┬──────────┘      │
│              │                                 │                  │
│              ▼                                 ▼                  │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │              APPLY / ROLLBACK DECISION                   │   │
│   │                                                          │   │
│   │  IF golden_metrics.improved OR golden_metrics.unchanged  │   │
│   │     → APPLY changes                                      │   │
│   │  ELSE                                                    │   │
│   │     → ROLLBACK + log failure reason                      │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### Логика валидации

```typescript
interface GoldenValidation {
  precision_delta: number;    // change vs baseline
  recall_delta: number;
  hallucination_delta: number;
  context_util_delta: number;
}

function shouldApplyChanges(golden: GoldenValidation): Decision {
  // Critical metrics MUST NOT degrade
  if (golden.hallucination_delta > 0.05) {
    return { apply: false, reason: 'hallucination increased on golden set' };
  }

  // Primary metrics should not degrade significantly
  if (golden.precision_delta < -0.05 || golden.recall_delta < -0.05) {
    return { apply: false, reason: 'primary metrics degraded on golden set' };
  }

  // At least one metric should improve
  const improved = [
    golden.precision_delta > 0.02,
    golden.recall_delta > 0.02,
    golden.hallucination_delta < -0.01,
    golden.context_util_delta > 0.02
  ].some(Boolean);

  if (!improved) {
    return { apply: false, reason: 'no improvement on golden set' };
  }

  return { apply: true, reason: 'golden set validation passed' };
}
```

---

## 1. Назначение (классическое описание)

Менеджер — это **центральный координирующий мета-агент**, который:

* принимает цели/ограничения от мета-пользователя (через фронт);
* переводит их в **формальные задачи** для Учителя, Симулятора и Настройщика;
* управляет жизненным циклом экспериментов и циклов самообучения;
* агрегирует результаты и возвращает их мета-пользователю в виде отчётов;
* следит за соблюдением политик автономии (что системе «разрешено» менять без человека).

Он **не** оценивает качество (это роль Учителя) и **не** трогает параметры напрямую (это Настройщик). Его зона — координация и протокол.

---

### 1.1. Границы ответственности

**Менеджер ДЕЛАЕТ:**

* принимает цели, приоритеты и ограничения от мета-пользователя;
* формирует и регистрирует эксперименты;
* вызывает Учителя для дизайна/анализа экспериментов;
* вызывает Симулятор для генерации данных;
* вызывает Настройщика для применения/отката параметров;
* ведёт «журнал обучения» и историю решений;
* генерирует человекочитаемые отчёты.

**Менеджер НЕ ДЕЛАЕТ:**

* не придумывает гипотез (что именно крутить и в какую сторону) — это Учитель;
* не считает метрики «сырых» логов — максимум вызывает готовые агрегаты/запросы;
* не меняет `experiment_parameters` напрямую;
* не лезет в пайплайн MaaS.

---

### 1.2. Интерфейсы (входы/выходы)

#### 2.1. Входы от мета-пользователя

Через фронт:

* цели обучения:

  * типичные форматы:

    * «снизить hallucination_rate по персональной памяти < 3%»;
    * «увеличить recall по preferences на +10%»;
    * «оптимизировать стоимость при сохранении текущего качества».
* ограничения:

  * что нельзя трогать (модели, RLS, типы данных);
  * max latency / max cost / max error_rate;
  * уровень автономии (что можно менять без подтверждения).
* приоритеты:

  * «главное — качество памяти» / «главное — дешево»;
  * порядок целей, если они конфликтуют.

#### 2.2. Входы от внутренних модулей

* от Учителя:

  * описания экспериментов (структура Experiment);
  * результаты экспериментов (metrics + verdict);
  * рекомендации по изменению параметров;
* от Настройщика:

  * статусы операций (успешно/ошибка);
  * информация об активных версиях параметров;
* от Симулятора:

  * статус прогонов (сколько диалогов прогнано, ошибки);
  * ссылка на собранную телеметрию.

#### 2.3. Выходы

* к Учителю:

  * формальные задания:

    * «спроектировать эксперимент под такие цели/constraints»;
    * «проанализировать результаты конкретного experiment_id»;
* к Симулятору:

  * команды запуска/остановки прогонов:

    * какие сценарии использовать;
    * какие варианты параметров тестировать (baseline/variant);
    * объём тестов (N диалогов, M шагов в каждом);
* к Настройщику:

  * заявки на изменения параметров:

    * подготовить экспериментальные конфигурации;
    * применить/откатить найденные изменения;
* к фронту/мета-пользователю:

  * дашборды / summary / логи решений.

---

### 1.3. Внутренняя структура Менеджера

Можно мыслить как набор подмодулей/сервисов:

1. **Goal Translator**

   * Принимает «человеческие» формулировки от мета-пользователя.
   * Превращает их в:

     * целевые метрики (primary/secondary);
     * допустимые импакт-факторы;
     * уровень автономии (auto/manual).

2. **Experiment Orchestrator**

   * Создаёт сущности `Experiment`:

     * id, цель, параметры, variants, success criteria.
   * Координирует:

     * запрос к Учителю (дизайн/анализ),
     * запуск Симулятора,
     * сбор статуса.
   * Отслеживает жизненный цикл эксперимента:

     * `planned → running → completed → analyzed`.

3. **Policy & Guardrail Manager**

   * Хранит и проверяет политики:

     * что можно тюнить автоматически;
     * разрешённые диапазоны параметров;
     * лимиты на число параллельных экспериментов;
     * уровни критичности (что требует ручного подтверждения).
   * Валидирует рекомендации Учителя перед тем, как отправить их Настройщику.

4. **Change Log & History**

   * Ведёт «журнал обучения»:

     * какие эксперименты запускались;
     * какие изменения параметров применены;
     * почему (ссылка на эксперименты и метрики);
     * кто инициировал (auto/manual).
   * Даёт API для фронта: «покажи историю изменений за период».

5. **Reporting & UX Layer**

   * Подготавливает человекочитаемые отчёты:

     * summary по экспериментам;
     * графики по ключевым метрикам (по данным из Telemetry);
     * алерты и рекомендации в понятном виде.

---

### 1.4. Основные сценарии работы Менеджера

#### 4.1. Новый цель/кампания обучения

1. Мета-пользователь задаёт через UI цель и ограничения.
2. Goal Translator:

   * валидирует ввод (есть ли нужные метрики, не конфликтуют ли constraints);
   * создаёт запись «кампании»/learning goal.
3. Менеджер вызывает Учителя:

   * «спроектируй набор экспериментов под эту goal».
4. Учитель возвращает набор `Experiment` → сохраняется в registry.

#### 4.2. Запуск эксперимента

1. Менеджер выбирает, какие эксперименты активировать (можно по очереди или пачкой).
2. Проверяет с Policy Manager:

   * не превышены ли лимиты;
   * не конфликтуют ли эксперименты по одним и тем же параметрам.
3. Формирует задачу Симулятору:

   * какие сценарии использовать;
   * split по вариантам (baseline/variant);
   * размер выборки.
4. Присваивает experiment_id, переводит эксперимент в статус `running`.

#### 4.3. Завершение и анализ

1. По условию (кол-во диалогов или время) Менеджер закрывает эксперимент как `completed`.
2. Запрашивает Учителя:

   * «проанализируй experiment_id, дай verdict и рекомендации».
3. Получает от Учителя:

   * winner/loser/inconclusive;
   * delta по метрикам;
   * предложения по изменению параметров + условия rollback.

#### 4.4. Применение изменений

1. Менеджер прогоняет рекомендации через Policy Manager:

   * допустимы ли такие изменения в авто-режиме;
   * нужно ли подтверждение мета-пользователя.
2. Если требуется approval:

   * показывает summary в UI;
   * ждёт явного «approve/reject».
3. После разрешения:

   * отправляет Настройщику формализованную «команду изменения параметров».
4. Логирует факт изменения и привязку к experiment_id.

#### 4.5. Обработка деградаций

1. Настройщик или Учитель сигналят о деградации (по DEGRADATION_RULES).
2. Менеджер:

   * фиксирует инцидент;
   * инициирует rollback через Настройщика;
   * создаёт запись в журнале;
   * показывает в UI «авто-откат по причине X».

---

### 1.5. Артефакты, с которыми работает Менеджер

* **Learning goals / campaigns**

  * id, цели, приоритеты, constraints, статус.
* **Experiments registry**

  * список экспериментов, статусы, ссылки на метрики.
* **Policies / guardrails**

  * описания разрешённых автономных действий.
* **Change log**

  * список параметр-изменений с причинами.
* **Reports**

  * сохранённые отчёты по циклам обучения (для UI).

---

### 1.6. Метрики качества самого Менеджера

Чего от него ждать и как понять, что он «нормально работает», а не превращается в болото:

* **Velocity:**

  * время от постановки цели до первого эксперимента;
  * время от завершения эксперимента до принятия решения.
* **Coverage:**

  * доля актуальных learning goals, по которым есть хотя бы один запущенный эксперимент.
* **Consistency:**

  * нет конфликтующих изменений одного параметра в разных экспериментах без явного разрешения.
* **Safety:**

  * нет изменений вне разрешённых политик;
  * количество авто-откатов по вине неправильной координации Менеджера ≈ 0.

---

### 1.7. Риски по роли Менеджера

Коротко, чтобы помнить при дизайне:

* риск 1: Менеджер становится «god-object» — тащит всё подряд. Нужно жёстко держать границу: он не считает метрики и не лезет в бизнес-логику Учителя.
* риск 2: путаница состояний экспериментов → нужен простой, но строгий lifecycle (`planned/running/completed/analyzed/applied/rolled_back`).
* риск 3: UI/Менеджер начинают обходить Настройщика и писать напрямую в конфиги — этого быть не должно вообще.

---

*Последнее обновление: 2025-11-28*
*Добавлена парадигма Meta-Agent, target metrics, async learning cycle*
