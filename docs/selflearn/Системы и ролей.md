# SELFLEARN — общая схема системы и ролей

Цель системы:
**делать MaaS лучше через непрерывные эксперименты**, где:

* меняются *конкретные импакт-факторы* (конфиги/промпты/параметры),
* качество измеряется *прозрачными метриками*,
* все решения можно объяснить, повторить и откатить.

Ниже — как все роли связаны в одном цикле обучения.

---

## 1. Роли в системе

### 1.1. Мета-пользователь (ты)

**Кто:** владелец системы, архитектор.
**Что делает:**

* формулирует цели обучения:
  «хочу меньше галлюцинаций», «улучшаем recall на preferences», «оптимизируем стоимость»;
* задаёт ограничения:
  бюджет, рамки автономии, что нельзя трогать (RLS, модели и т.д.);
* утверждает или отклоняет крупные изменения.

---

### 1.2. Менеджер (Experiment Manager / Coordinator)

**Кто:** верхнеуровневый «диспетчер» всей стаи. Может быть как LLM-агент + немного кода.

**Ответственность:**

* единственная точка общения с мета-пользователем;
* переводит твоё «хочу» в формальные сущности:

  * цели → таргет-метрики,
  * ограничения → guards/политики;
* координирует остальные роли:

  * запускает эксперименты,
  * собирает результаты от Учителя,
  * даёт команды Настройщику,
  * ведёт «журнал обучения» (историю гипотез и изменений).

---

### 1.3. MaaS-ассистент (Ученик)

**Кто:** основной ассистент, который использует память (MaaS).

**Что важно:**

* он работает **как в проде**: тот же пайплайн, те же импакт-факторы;
* предмет экспериментов — **качество его поведения**:

  * точность памяти,
  * персонализация,
  * латентность,
  * стоимость.

Ученик = «MaaS + текущая версия параметров/конфигов».

---

### 1.4. Симулятор пользователя (User Emulator)

**Кто:** модуль, который играет роль реального пользователя.

**Задача:**

* генерить **реалистичные диалоги**, а не одиночные запросы:

  * сценарий/проект,
  * цель пользователя,
  * persona,
  * цепочки запросов и уточнений.

**Ограничение:**
эмулятор не знает внутренности MaaS и ходит к нему **как внешний клиент**.

---

### 1.5. Учитель (Evaluator / Researcher / Analyst)

**Кто:** связка LLM-агентов + аналитических скриптов поверх Telemetry.

**Отвечает за:**

* оценку качества:

  * метрики из `METRICS.md`,
  * LLM-judge (relevance, utilization, hallucinations и т.д.);
* формирование гипотез:

  * какие импакт-факторы менять,
  * в какую сторону и зачем;
* планирование и анализ экспериментов:

  * дизайн A/B,
  * анализ результатов,
  * вывод: «оставить / откатить / попробовать следующее».

Выдаёт **рекомендации в формальном виде**:

> изменить `retrieval.top_k: 3 → 2`, ожидаемый эффект: precision↑, recall≈, основание: результаты эксперимента X.

---

### 1.6. Настройщик (Tuner)

**Кто:** чистый код, без LLM.

**Функция:**

* принимает решения Учителя **в машинном формате**:

  * параметр, старое значение, новое значение, причина, границы, кто инициировал;
* делает всё грязное руками:

  * создаёт новую версию параметров в `experiment_parameters`,
  * активирует/откатывает версии,
  * следит за диапазонами, safety-ограничениями;
* никогда ничего «не придумывает» — только выполняет и валидирует.

Настройщик — это «руки», не «мозги».

---

## 2. Общая среда (Shared Substrate)

У всех ролей общие артефакты:

* **MaaS + конфиги импакт-факторов**
  (то, что описано в `IMPACT_FACTORS.md` / `experiment_parameters`).

* **Телеметрия и метрики**
  (`telemetry_events`, `pipeline_runs` и агрегации из `METRICS.md`).

* **Golden Dataset + сценарии**
  (`GoldenExample`, `sim_scenarios.json`, регистр тестов).

* **Журнал экспериментов и версий параметров**
  (`experiment_parameters`, `experiment_results`, change log).

---

## 3. Как всё работает в одном цикле обучения

### Шаг 0. Постановка задачи (Мета-пользователь ↔ Менеджер)

* Ты говоришь Менеджеру на человеческом:

  > «Сократить галлюцинации по личной памяти < 3%, не потеряв recall; стоимость не трогаем.»

* Менеджер переводит в формальный запрос:

  * primary-метрики: `hallucination_rate`, `retrieval_recall`;
  * constraints: `token_cost`, `latency`;
  * допустимые импакт-факторы: `System Prompt`, `top_k`, `temperature` (без смены модели).

---

### Шаг 1. План эксперимента (Менеджер ↔ Учитель)

* Менеджер просит Учителя:

  > «Спроектируй эксперимент(ы) под такие цели и ограничения.»

* Учитель:

  * выбирает, какие параметры варьировать (например, `top_k`, `temperature`);
  * задаёт baseline/variant;
  * прописывает success-criteria (формат из `SELFLEARN` → `Experiment`).

На выходе: **описание эксперимента** (YAML/JSON), которое понимает Настройщик и Sim Runner.

---

### Шаг 2. Подготовка параметров (Учитель → Настройщик)

* Учитель выдаёт Тунеру:

  ```json
  {
    "type": "prepare_experiment",
    "experiment_id": "top_k_3_vs_2",
    "variants": [
      { "name": "baseline", "params": { "retrieval.top_k": 3 } },
      { "name": "variant",  "params": { "retrieval.top_k": 2 } }
    ]
  }
  ```

* Настройщик:

  * создаёт записи в `experiment_parameters`,
  * помечает baseline / test варианта,
  * не активирует их глобально, а подвязывает к эксперименту.

---

### Шаг 3. Генерация опыта (Симулятор ↔ MaaS)

Запускается эксперимент (обычно в OFFLINE режиме):

1. **Симулятор пользователя** (User Emulator):

   * выбирает сценарии и personas (project, intent, persona);
   * генерирует диалоги (threads) с ассистентом:

     * задаёт вопросы,
     * уточняет,
     * ведёт себя как реальный, но synthetic пользователь.

2. **MaaS (Ученик)**:

   * обрабатывает запросы как обычно:

     * retrieval, память, system prompt, ответ;
   * работает:

     * то на baseline-параметрах,
     * то на variant-параметрах (через assignment правила A/B).

3. Все запросы/ответы идут через обычный пайплайн и пишутся в:

   * `pipeline_runs`,
   * `telemetry_events` (с `experiment_id`, `variant`, `cycle_type`).

**Важно:**
С точки зрения MaaS это всего лишь ещё один клиент; никакого «отдельного режима тестов».

---

### Шаг 4. Оценка (Учитель)

Когда набралось достаточно данных:

* Учитель:

  * считает метрики по baseline и variant (SQL + агрегаты из `METRICS.md`);
  * прогоняет LLM-judge там, где нужен качественный разбор (relevance, utilization, hallucinations);
  * применяет критерии значимости (t-test, пороги delta, p-value).

Результат:

* **формальный verdict** по каждому эксперименту:

  * `winner` / `loser` / `inconclusive`,
  * фактические дельты по метрикам,
  * побочные эффекты (например, latency выросла).

---

### Шаг 5. Решение и интервенция (Учитель → Менеджер → Настройщик)

1. Учитель формирует рекомендации:

   ```json
   {
     "action": "update_params",
     "reason": "top_k=2 даёт +8% precision при -2% recall, hallucinations ↓",
     "changes": [
       { "param": "retrieval.top_k", "from": 3, "to": 2 }
     ],
     "rollback_conditions": { "precision_drop": 0.1, "cycles": 3 }
   }
   ```

2. Менеджер:

   * агрегирует результаты нескольких экспериментов,
   * проверяет, нет ли конфликтов,
   * показывает тебе summary (человеческий отчёт),
   * если нужно — спрашивает явное «да/нет» для критичных изменений.

3. Настройщик:

   * создаёт новую активную версию параметров,
   * логирует причину (reason + experiment_id),
   * запускает авто-rollback правила (из SELFLEARN).

---

### Шаг 6. Мониторинг и rollback (Настройщик + Учитель)

После применения новых параметров:

* обычные ONLINE-диалоги (реальные пользователи) продолжаются;
* метрики онлайн-режима мониторятся:

  * если всё в норме → параметры остаются;
  * если деградация по правилам `DEGRADATION_RULES` → авто-rollback через Настройщика.

Учитель периодически сопоставляет:

* качество на golden dataset,
* качество на реальных запросах (user feedback, жалобы).

---

### Шаг 7. Обратная связь мета-пользователю (Менеджер ↔ ты)

Менеджер готовит:

* короткий отчёт после цикла:

  * что тестировали,
  * что выиграло/проиграло,
  * какой прирост метрик,
  * какие гипотезы отклонены;
* обновлённую карту гипотез:

  * что ещё стоит проверить,
  * куда дальше копать.

Ты решаешь:

* продолжать авто-режим в тех же границах,
* сузить/расширить зону автономии,
* поставить новые приоритеты (например, переключиться со «скорости» на «надёжность памяти»).

---

## 4. Как роли делят ответственность

Чтобы не путалось:

* **Симулятор** — генерирует опыт (диалоги).
  Не оценивает качество, не трогает параметры.

* **MaaS-ассистент (Ученик)** — просто работает по текущим настройкам.
  Его «качество» — предмет измерения.

* **Учитель** — думает, строит гипотезы, читает метрики.
  Не лезет напрямую в конфиги, всегда говорит в формате «предлагаю изменить X→Y».

* **Настройщик** — меняет параметры и следит за safety.
  Не придумывает ничего нового, только аккуратно крутит ручки.

* **Менеджер** — общается с тобой и дирижирует остальными:
  планирует эксперименты, принимает/коммуницирует решения, ведёт историю.

* **Ты** — задаёшь цели и границы игры.

---

## 5. Коротко «за» и «против» такого дизайна

**Плюсы:**

1. Чёткое разделение ролей — легко локализовать баг: в симуляторе, в учителе, в тюнере или в самом MaaS.
2. Все интервенции проходят через Настройщика и версионирование — значит, всё можно объяснить и откатить.
3. Менеджер даёт тебе одну точку входа, без необходимости руками разбираться во всех слоях сразу.

**Минусы / риски:**

1. Сложность в том, чтобы эмулятор + golden set действительно покрывали «реальных» пользователей, а не само-референсный мир.
2. Учитель (LLM-часть) сам подвержен галлюцинациям и bias — нужны жёсткие рамки и проверки (SQL-метрики как источник истины).
3. Менеджер легко превратится в «свалку обязанностей», если не задать ему явный контракт (что входит, что не входит).

## Интерфейс мета‑пользователь ↔ Менеджер

Мета‑пользователь (ты) не общается напрямую с отдельными ролями системы. Взаимодействие идёт через один фронт‑интерфейс, «лицом» которого выступает роль Менеджера:

* в UI мета‑пользователь:

  * запускает и останавливает эксперименты и циклы самообучения;
  * задаёт/меняет настройки и границы автономии (что можно тюнить автоматически, диапазоны параметров, лимиты откатов и т.п.);
  * просматривает дашборды и отчёты (метрики, сравнение вариантов, алерты, историю изменений параметров);
  * вручную утверждает или отклоняет предложения Учителя, если они попадают в «manual‑зону».

Менеджер внутри системы отвечает за трансляцию этих действий фронта в конкретные задачи для Симулятора, Учителя и Настройщика.

---

## Цель обучения (что именно оптимизируем)

Практическая цель self‑learning — не «делать систему умнее вообще», а улучшать работу MaaS по явной функции качества.

В базовой формулировке цель такая:

* **Primary:** максимально повысить качество работы памяти:

  * увеличить Retrieval Precision и Retrieval Recall;
  * снизить Hallucination Rate;
  * повысить Context Utilization.
* **Под ограничениями:** удерживать Latency, Error Rate и Token Cost в пределах заданных таргетов.
* **Дополнительно:** оптимизировать под реальное распределение задач пользователей, а не только под синтетический golden‑dataset.

Иными словами, система обучения пытается найти такие значения импакт‑факторов, при которых:

> суммарное качество (через primary‑метрики) максимизируется,
> а системные ограничения (латентность, стоимость, надёжность, безопасность)
> остаются в допустимых пределах.

Учитель формулирует и проверяет гипотезы именно относительно этой цели: что изменить в импакт‑факторах, чтобы сделать следующий шаг в сторону лучшей конфигурации, не ломая constraints.

Ок, зафиксирую это без магии с холстом.

1. **Суть цели обучения** — да, именно так:

> Цель — найти такие значения импакт-факторов, при которых качество работы памяти
> *(Precision / Recall / Context Utilization, минимум галлюцинаций)*
> максимизируется при ограничениях по **латентности, стоимости и надёжности**.

2. **Контекст MaaS** — тоже важный кусок, его надо прямо писать в док:

> MaaS — внешний сервис памяти, к которому можно прикрутить любой фронт
> и любой ассистент. Он нужен во всех проектах, где недостаточно просто
> слать разовые инференсы, а нужна **устойчивая, управляемая память**.

3. **Форма цели (очень важно для всей системы)**:

> Цель обучения **всегда выражается в виде конкретных изменений**:
> промптов, конфигов и других импакт-факторов,
> а не в виде абстрактных «улучшить качество».

То есть для SELFLEARN / Manager-а цель должна быть не:

* «повысить качество памяти»,

а в формате:

* «найти такую связку `top_k`, `relevance_weight`, `recency_weight`, `system_prompt_vN`,
  при которой на golden-dataset выполняются target-метрики при заданных ограничениях».

Я пытался сейчас прямо патчнуть текст в холсте через инструмент, но регулярка не нашла старую строку, и обновление упало — поэтому в интерфейсе ты изменений не увидишь. Придётся руками вставить формулировку выше в блок про «Цель обучения» (или я могу тебе выдать целиком готовый блок/раздел, а ты просто заменишь его в канвасе).

Ок, разверну без воды, но так, чтобы это уже можно было врезать в док.

---

### 1. Что именно означает «найти такие значения импакт-факторов»

Перевод на инженерный язык:

* У нас есть **вектор параметров**:
  `θ = {top_k, relevance_weight, recency_weight, keyword_count, system_prompt_version, temperature, …}`
* Есть **функция качества** `Q(θ)`, которая считается по метрикам:

  * Primary: `precision`, `recall`, `context_utilization`, `hallucination_rate`;
  * Secondary: `latency`, `token_cost`, `error_rate`.
* Есть **ограничения**:
  `latency ≤ L_max`, `cost ≤ C_max`, `error_rate ≤ E_max` и т.п.

Тезис «найти такие значения импакт-факторов» =
**найти такую конфигурацию **``**, при которой:**

* Primary-метрики **максимально хороши**,
* Secondary-метрики **остаются в допустимых диапазонах**,
* и всё это получено на **реалистичных сценариях**, а не на искусственном одном тесте.

---

### 2. Зачем вообще так заморачиваться

Потому что MaaS — это **универсальный сервис памяти**:

* его можно подвесить к **любому ассистенту** и **любому фронту**;
* он должен работать:

  * с разными типами запросов,
  * при разных нагрузках,
  * в разных продуктах.

Если не зафиксировать цель через импакт-факторы и метрики, получится классическая хрень:

* «ощущается лучше/хуже»,
* «иногда стало умнее, иногда тупее»,
* никто не понимает, *что именно* поменяли и почему.

Твоя формулировка делает цель **жёсткой и операциональной**:

> мы не «улучшаем ИИ»,
> мы **тюним конкретные ручки**, пока метрики памяти не станут лучше при тех же или приемлемых затратах.

---

### 3. Как это выглядит в практическом цикле

1. **Фиксируем функцию качества**:

   * Primary-метрики: цели типа
     `precision ≥ 0.8`, `recall ≥ 0.7`, `hallucination_rate ≤ 0.05`, `context_utilization ≥ 0.9`.
   * Constraints:
     `latency_p95 ≤ 5s`, `cost_per_req ≤ $0.01`, `error_rate ≤ 1%`.
2. **Выбираем подмножество импакт-факторов**, с которыми сейчас работаем:

   * например: `top_k`, `relevance_weight`, `recency_weight`, `temperature`, `system_prompt_version`.
3. **Учитель запускает эксперименты**:

   * перебирает разные `θ` (в явных вариантах),
   * гоняет их через симулятор/Golden dataset,
   * считает метрики.
4. **Настройщик фиксирует победителя**:

   * выбирается конфигурация, которая лучше по primary-метрикам,
   * не нарушает constraints,
   * записывается как новая активная версия.
5. **Дальше цикл повторяется**:

   * новая гипотеза,
   * следующий кусок параметров,
   * постепенное «ползучее» улучшение.

---

### 4. Что важно НЕ включать в цель

Что **не входит** в этот тезис (и это плюс):

* «сделать модель в целом умнее» — это уже уровень выбора LLM, а не MaaS;
* «делать магические UX-улучшения» — это про фронты;
* «перепридумывать архитектуру» — это отдельные архитектурные решения, а не тюнинг.

Цель **узкая и честная**:
**мы оптимизируем только то, что контролируется через импакт-факторы MaaS.**

---

### 5. Узкие места этой формулировки (по-честному)

**Слабые точки:**

1. Метрики могут не полностью ловить «реальную полезность» для живого юзера.
   Precision/Recall по памяти ≠ удовлетворённость пользователя.
2. Есть риск Goodhart’а:
   как только метрика становится целью, система начнёт её «играть» (например, снизим hallucination_rate, просто чаще говоря «не знаю»).
3. Golden dataset и симулятор могут быть **не репрезентативны** относительно живого трафика.

**Как проверять:**

* всегда держать **онлайн-метрики** (по реальным юзерам) рядом с offline-result;
* добавлять **user feedback** как отдельный канал проверки;
* периодически валидировать, что распределение сценариев в симуляторе похоже на реальное (или хотя бы покрывает его).

---

Если хочешь, могу отдельно оформить это как блок `## Цель обучения` для вставки в `SELFLEARN.md` / `Selflearn Overview` в том же «жёстком» стиле.
