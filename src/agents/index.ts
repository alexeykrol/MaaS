/**
 * Agent Implementations
 *
 * ‚úÖ Analyzer - —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ LSM —á–µ—Ä–µ–∑ keyword matching
 * ‚úÖ Assembler - —Ä–µ–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ LSM + raw_logs
 * ‚úÖ FinalResponder - —Ä–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏
 *
 * –í—Å–µ –∞–≥–µ–Ω—Ç—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã.
 */

import { pool } from '../utils/db';
import { logger } from '../utils/logger';
import { createChatCompletion } from '../utils/openai';

/**
 * Helper: Sleep function
 */
function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Analyzer Agent - Memory Retriever
 *
 * –ó–∞–¥–∞—á–∞: –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–∑ LSM
 * –°—Ç–∞—Ç—É—Å—ã: NEW ‚Üí ANALYZING ‚Üí ANALYZED
 *
 * –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (v0.2):
 * - –ò–∑–≤–ª–µ–∫–∞–µ—Ç keywords –∏–∑ user_query
 * - –ò—â–µ—Ç –≤ lsm_storage —á–µ—Ä–µ–∑ semantic_tags && keywords (PostgreSQL array overlap)
 * - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ 3 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö memories
 * - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ analysis_result
 *
 * TODO v0.3: Vector search –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
 */
export async function runAnalyzer(pipelineId: string): Promise<void> {
  logger.info(`[Analyzer] üîç Starting for ${pipelineId}`);

  try {
    // –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ã–π –∑–∞—Ö–≤–∞—Ç –∑–∞–¥–∞—á–∏
    const result = await pool.query(
      `UPDATE pipeline_runs
       SET status = 'ANALYZING', updated_at = NOW()
       WHERE id = $1 AND status = 'NEW'
       RETURNING *`,
      [pipelineId]
    );

    if (result.rowCount === 0) {
      logger.warn(`[Analyzer] Task ${pipelineId} already taken or invalid status`);
      return;
    }

    const run = result.rows[0];
    logger.info(`[Analyzer] Processing query: "${run.user_query.substring(0, 50)}..."`);

    // Extract keywords from query
    const keywords = extractSimpleKeywords(run.user_query);
    logger.info(`[Analyzer] Extracted keywords: [${keywords.join(', ')}]`);

    // Search LSM for relevant memories (v0.1: keyword-based search)
    // Uses PostgreSQL array overlap operator (&&) to match semantic_tags
    const memoryResult = await pool.query(
      `SELECT summary_text, semantic_tags, time_bucket
       FROM lsm_storage
       WHERE user_id = $1
         AND semantic_tags && $2
       ORDER BY created_at DESC
       LIMIT 3`,
      [run.user_id, keywords]
    );

    const memories = memoryResult.rows.map(row => ({
      summary_text: row.summary_text,
      semantic_tags: row.semantic_tags,
      time_bucket: row.time_bucket
    }));

    logger.info(`[Analyzer] Found ${memories.length} memories from LSM (${keywords.length} keywords)`);

    // –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ (—Ñ–æ—Ä–º–∞—Ç –¥–ª—è Assembler)
    const analysis = {
      memories,
      search_keywords: keywords,
      timestamp: new Date().toISOString(),
    };

    // –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    await pool.query(
      `UPDATE pipeline_runs
       SET
         analysis_result = $1,
         status = 'ANALYZED',
         updated_at = NOW()
       WHERE id = $2`,
      [JSON.stringify(analysis), pipelineId]
    );

    logger.info(`[Analyzer] ‚úÖ Completed for ${pipelineId}`);
  } catch (error) {
    logger.error(`[Analyzer] ‚ùå Error for ${pipelineId}:`, error);
    throw error;
  }
}

/**
 * Extract simple keywords from query (v0.1 - basic implementation)
 *
 * TODO v0.2: Use OpenAI for better extraction
 * TODO v0.3: Use embeddings for semantic search
 */
function extractSimpleKeywords(query: string): string[] {
  // –ü—Ä–æ—Å—Ç–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è: —É–±—Ä–∞—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, –≤–∑—è—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
  const stopWords = ['the', 'a', 'an', 'is', 'are', 'was', 'were', 'what', 'how', 'when', 'where', 'why', 'to', 'for', 'of', 'in', 'on', 'at'];

  const words = query.toLowerCase()
    .replace(/[^a-z0-9\s]/g, '')
    .split(/\s+/)
    .filter(w => w.length > 2 && !stopWords.includes(w));

  return [...new Set(words)]; // Unique words
}

/**
 * Assembler Agent - Context Builder
 *
 * –ó–∞–¥–∞—á–∞: –°–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM —Å–æ–≥–ª–∞—Å–Ω–æ /context/format.md
 * –°—Ç–∞—Ç—É—Å—ã: ANALYZED ‚Üí ASSEMBLING ‚Üí READY
 *
 * –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (v0.1):
 * - –ß–∏—Ç–∞–µ—Ç analysis_result –æ—Ç Analyzer (memories –∏–∑ LSM)
 * - –ß–∏—Ç–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–∏–∞–ª–æ–≥–∞ –∏–∑ raw_logs
 * - –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç: SYSTEM ROLE + PREVIOUS CONTEXT (LSM) + RECENT CONVERSATION + CURRENT QUERY
 * - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ final_context_payload –¥–ª—è FinalResponder
 *
 * TODO v0.2: –£–º–Ω–∞—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
 */
export async function runAssembler(pipelineId: string): Promise<void> {
  logger.info(`[Assembler] üì¶ Starting for ${pipelineId}`);

  try {
    // –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ã–π –∑–∞—Ö–≤–∞—Ç
    const result = await pool.query(
      `UPDATE pipeline_runs
       SET status = 'ASSEMBLING', updated_at = NOW()
       WHERE id = $1 AND status = 'ANALYZED'
       RETURNING *`,
      [pipelineId]
    );

    if (result.rowCount === 0) {
      logger.warn(`[Assembler] Task ${pipelineId} already taken or invalid status`);
      return;
    }

    const run = result.rows[0];
    logger.info(`[Assembler] Building context for: "${run.user_query.substring(0, 50)}..."`);

    // –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ (–æ—Ç Analyzer)
    const analysis = run.analysis_result || { memories: [] };

    // –ü–æ–ª—É—á–∏—Ç—å recent conversation –∏–∑ raw_logs
    // –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2-3 –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–∞ (query + answer pairs)
    const logsResult = await pool.query(
      `SELECT
         log_type,
         log_data,
         created_at
       FROM raw_logs
       WHERE user_id = $1
         AND pipeline_run_id != $2
       ORDER BY created_at ASC`,
      [run.user_id, pipelineId]
    );

    // –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ª–æ–≥–∏ –≤ –ø–∞—Ä—ã query-answer (logs ordered ASC, so query comes before answer)
    const recentLogs: Array<{ query: string; answer: string }> = [];
    for (let i = 0; i < logsResult.rows.length; i += 2) {
      const queryLog = logsResult.rows[i];
      const answerLog = logsResult.rows[i + 1];

      if (queryLog && answerLog && queryLog.log_type === 'USER_QUERY' && answerLog.log_type === 'SYSTEM_RESPONSE') {
        recentLogs.push({
          query: queryLog.log_data.query,
          answer: answerLog.log_data.answer
        });
      }
    }

    // Limit to last 3 exchanges (format.md spec)
    const limitedLogs = recentLogs.slice(-3);

    logger.info(`[Assembler] Found ${limitedLogs.length} recent exchanges from raw_logs`);

    // –°–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–≥–ª–∞—Å–Ω–æ /context/format.md
    const context = buildContextString(
      run.user_query,
      analysis.memories || [],
      limitedLogs
    );

    logger.info(`[Assembler] Context built: ${context.length} chars`);

    // –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    await pool.query(
      `UPDATE pipeline_runs
       SET
         final_context_payload = $1,
         status = 'READY',
         updated_at = NOW()
       WHERE id = $2`,
      [context, pipelineId]
    );

    logger.info(`[Assembler] ‚úÖ Completed for ${pipelineId}`);
  } catch (error) {
    logger.error(`[Assembler] ‚ùå Error for ${pipelineId}:`, error);
    throw error;
  }
}

/**
 * Build context string according to /context/format.md v0.1
 *
 * @param currentQuery - User's current question
 * @param memories - Retrieved memories from LSM (from Analyzer)
 * @param recentLogs - Recent conversation history
 * @returns Formatted context string
 */
function buildContextString(
  currentQuery: string,
  memories: Array<{ summary_text: string }>,
  recentLogs: Array<{ query: string; answer: string }>
): string {
  let context = '';

  // Section 1: SYSTEM ROLE (always included)
  context += `SYSTEM ROLE:\n`;
  context += `You are a helpful AI assistant with long-term memory of past conversations with this user.\n\n`;

  // Section 2: PREVIOUS CONTEXT (from long-term memory) - optional
  if (memories && memories.length > 0) {
    context += `PREVIOUS CONTEXT (from long-term memory):\n`;
    memories.forEach(m => {
      context += `${m.summary_text}\n\n`;
    });
  }

  // Section 3: RECENT CONVERSATION - optional
  if (recentLogs && recentLogs.length > 0) {
    context += `RECENT CONVERSATION:\n`;
    recentLogs.forEach(log => {
      context += `User: ${log.query}\n`;
      context += `Assistant: ${log.answer}\n\n`;
    });
  }

  // Section 4: CURRENT QUERY (always included)
  context += `CURRENT QUERY:\n`;
  context += `${currentQuery}\n\n`;

  // Section 5: INSTRUCTION (always included)
  context += `Please respond naturally, referencing past context when relevant.`;

  return context;
}

/**
 * Final Responder Agent Stub
 *
 * –ó–∞–¥–∞—á–∞: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
 * –°—Ç–∞—Ç—É—Å—ã: READY ‚Üí RESPONDING ‚Üí COMPLETED
 */
export async function runFinalResponder(pipelineId: string): Promise<void> {
  logger.info(`[FinalResponder] üí¨ Starting for ${pipelineId}`);

  try {
    // –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ã–π –∑–∞—Ö–≤–∞—Ç
    const result = await pool.query(
      `UPDATE pipeline_runs
       SET status = 'RESPONDING', updated_at = NOW()
       WHERE id = $1 AND status = 'READY'
       RETURNING *`,
      [pipelineId]
    );

    if (result.rowCount === 0) {
      logger.warn(`[FinalResponder] Task ${pipelineId} already taken or invalid status`);
      return;
    }

    const run = result.rows[0];
    logger.info(`[FinalResponder] Generating response for: "${run.user_query.substring(0, 50)}..."`);

    // –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç Assembler (–µ—Å–ª–∏ –µ—Å—Ç—å)
    const contextPayload = run.final_context_payload || run.user_query;

    // –í—ã–∑–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ OpenAI
    logger.info('[FinalResponder] ü§ñ Calling OpenAI...');
    const answer = await createChatCompletion({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: 'You are a helpful AI assistant with access to long-term memory. Provide clear, accurate, and contextual responses.'
        },
        {
          role: 'user',
          content: contextPayload
        }
      ],
      temperature: 0.7,
      max_tokens: 2000
    });

    logger.info(`[FinalResponder] ‚úÖ OpenAI responded (${answer.length} chars)`);

    // –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    await pool.query(
      `UPDATE pipeline_runs
       SET
         final_answer = $1,
         status = 'COMPLETED',
         updated_at = NOW()
       WHERE id = $2`,
      [answer, pipelineId]
    );

    // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ raw_logs (–¥–ª—è –±—É–¥—É—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Archivist)
    logger.info(`[FinalResponder] üìù Logging to raw_logs...`);

    // Log 1: USER_QUERY
    await pool.query(
      `INSERT INTO raw_logs (pipeline_run_id, user_id, log_type, log_data)
       VALUES ($1, $2, 'USER_QUERY', $3)`,
      [
        pipelineId,
        run.user_id,
        JSON.stringify({
          query: run.user_query,
          timestamp: new Date().toISOString()
        })
      ]
    );

    // Log 2: SYSTEM_RESPONSE
    await pool.query(
      `INSERT INTO raw_logs (pipeline_run_id, user_id, log_type, log_data)
       VALUES ($1, $2, 'SYSTEM_RESPONSE', $3)`,
      [
        pipelineId,
        run.user_id,
        JSON.stringify({
          answer: answer,
          timestamp: new Date().toISOString()
        })
      ]
    );

    logger.info(`[FinalResponder] ‚úÖ Logged 2 entries to raw_logs`);
    logger.info(`[FinalResponder] ‚úÖ Completed for ${pipelineId}`);
  } catch (error) {
    logger.error(`[FinalResponder] ‚ùå Error for ${pipelineId}:`, error);
    throw error;
  }
}
